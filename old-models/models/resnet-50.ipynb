{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './../datasets/dataset1'  # Update this to your dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28103 images belonging to 5 classes.\n",
      "Found 23416 images belonging to 5 classes.\n",
      "Found 11708 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "num_classes = 5\n",
    "validation_split = 0.2  # 20% of the data will be used for validation\n",
    "test_split = 0.1\n",
    "\n",
    "# Data preparation without augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_split\n",
    ")\n",
    "\n",
    "# Data augmentation for training data\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     validation_split=validation_split\n",
    "# )\n",
    "\n",
    "# Generators for training and validation\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_split / (validation_split + test_split)\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Data preparation for testing\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=test_split / (validation_split + test_split)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the ResNet50 model, excluding the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    return tf.py_function(\n",
    "        lambda y_true, y_pred: balanced_accuracy_score(\n",
    "            y_true.numpy(), y_pred.numpy()),\n",
    "        (y_true, y_pred),\n",
    "        tf.float64)\n",
    "\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), tf.int32)\n",
    "    y_pred = tf.cast(tf.argmax(y_pred, axis=1), tf.int32)\n",
    "\n",
    "    def compute_fscore(y_true, y_pred):\n",
    "        _, _, fscore, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='macro', zero_division=0)\n",
    "        return fscore\n",
    "\n",
    "    fscore = tf.py_function(\n",
    "        compute_fscore, (y_true, y_pred), tf.float64)\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, roc_auc_score, log_loss\n",
    "\n",
    "# Define custom F1 score metrics\n",
    "def f1_macro(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    def compute_f1(y_true, y_pred):\n",
    "        y_true = y_true.numpy()\n",
    "        y_pred = y_pred.numpy()\n",
    "        _, _, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "        return f1\n",
    "\n",
    "    f1 = tf.py_function(compute_f1, (y_true, y_pred), tf.float64)\n",
    "    return f1\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    def compute_f1(y_true, y_pred):\n",
    "        y_true = y_true.numpy()\n",
    "        y_pred = y_pred.numpy()\n",
    "        _, _, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        return f1\n",
    "\n",
    "    f1 = tf.py_function(compute_f1, (y_true, y_pred), tf.float64)\n",
    "    return f1\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba):\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Precision, Recall, F1 Score\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # ROC-AUC (One-vs-Rest)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "    \n",
    "    # Log Loss\n",
    "    logloss = log_loss(y_true, y_pred_proba)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'roc_auc': roc_auc,\n",
    "        'log_loss': logloss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "426/878 [=============>................] - ETA: 2:07 - loss: 0.8823 - accuracy: 0.7322 - categorical_accuracy: 0.7322 - auc: 0.8866 - balanced_accuracy: 0.2641 - fscore: 0.2239 - precision: 0.7321 - recall: 0.7265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohit\\anaconda3\\envs\\AML\\lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 454s 510ms/step - loss: 0.8735 - accuracy: 0.7349 - categorical_accuracy: 0.7349 - auc: 0.8888 - balanced_accuracy: 0.2643 - fscore: 0.2244 - precision: 0.7349 - recall: 0.7322 - val_loss: 0.8674 - val_accuracy: 0.7349 - val_categorical_accuracy: 0.7349 - val_auc: 0.8910 - val_balanced_accuracy: 0.2647 - val_fscore: 0.2248 - val_precision: 0.7349 - val_recall: 0.7349\n",
      "Epoch 2/15\n",
      "878/878 [==============================] - 444s 506ms/step - loss: 0.8704 - accuracy: 0.7347 - categorical_accuracy: 0.7347 - auc: 0.8903 - balanced_accuracy: 0.2673 - fscore: 0.2268 - precision: 0.7347 - recall: 0.7347 - val_loss: 0.8727 - val_accuracy: 0.7349 - val_categorical_accuracy: 0.7349 - val_auc: 0.8919 - val_balanced_accuracy: 0.2675 - val_fscore: 0.2271 - val_precision: 0.7349 - val_recall: 0.7349\n",
      "Epoch 3/15\n",
      "878/878 [==============================] - ETA: 0s - loss: 0.8717 - accuracy: 0.7347 - categorical_accuracy: 0.7347 - auc: 0.8896 - balanced_accuracy: 0.2691 - fscore: 0.2283 - precision: 0.7347 - recall: 0.7347"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "learning_rate = 3.9e-5\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.AUC(),\n",
    "    balanced_accuracy,\n",
    "    fscore,\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall()\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=metrics)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_true = test_generator.classes\n",
    "y_pred = model.predict(test_generator, steps=test_generator.samples // batch_size)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Evaluate additional metrics\n",
    "metrics = evaluate_model(y_true, y_pred_classes, y_pred)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Unfreeze some layers of the base model for fine-tuning\n",
    "# for layer in base_model.layers[:143]:\n",
    "#     layer.trainable = False\n",
    "# for layer in base_model.layers[143:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# # Recompile the model\n",
    "# model.compile(optimizer=Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Continue training\n",
    "# model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.samples // batch_size,\n",
    "#     validation_steps=validation_generator.samples // batch_size,\n",
    "#     validation_data=validation_generator,\n",
    "#     epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 76s 208ms/step - loss: 0.8647 - accuracy: 0.7345\n",
      "Test loss: 0.8646619915962219\n",
      "Test accuracy: 0.734503448009491\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
