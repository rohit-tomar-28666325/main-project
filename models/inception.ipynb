{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for the dataset\n",
    "data_dir = './../datasets/dataset1'\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 8\n",
    "epochs = 10\n",
    "num_classes = 5\n",
    "validation_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "# Data preparation for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=validation_split + test_split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_split / (validation_split + test_split)\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=test_split / (validation_split + test_split)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Compute the class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights: \", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom weighted categorical cross-entropy loss function\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        weights_tensor = tf.reduce_sum(weights * y_true, axis=-1)\n",
    "        unweighted_losses = categorical_crossentropy(y_true, y_pred)\n",
    "        weighted_losses = unweighted_losses * weights_tensor\n",
    "        return tf.reduce_mean(weighted_losses)\n",
    "    return loss\n",
    "\n",
    "# Define the custom loss function using the computed class weights\n",
    "loss_fn = weighted_categorical_crossentropy(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    return tf.py_function(\n",
    "        lambda y_true, y_pred: balanced_accuracy_score(\n",
    "            y_true.numpy(), y_pred.numpy()),\n",
    "        (y_true, y_pred),\n",
    "        tf.float64)\n",
    "\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), tf.int32)\n",
    "    y_pred = tf.cast(tf.argmax(y_pred, axis=1), tf.int32)\n",
    "\n",
    "    def compute_fscore(y_true, y_pred):\n",
    "        _, _, fscore, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='macro', zero_division=0)\n",
    "        return fscore\n",
    "\n",
    "    fscore = tf.py_function(\n",
    "        compute_fscore, (y_true, y_pred), tf.float64)\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 3.9e-5\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.AUC(),\n",
    "    balanced_accuracy,\n",
    "    fscore,\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"A single label was found in y_true and y_pred.\")\n",
    "warnings.filterwarnings('ignore', message=\"y_pred contains classes not in y_true\") \n",
    "warnings.filterwarnings('ignore', message=\"A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the InceptionV3 model, excluding the top layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=loss_fn, metrics=metrics)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
