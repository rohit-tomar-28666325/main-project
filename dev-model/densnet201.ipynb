{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "num_classes = 5\n",
    "validation_split = 0.2\n",
    "test_split = 0.1\n",
    "print(\"Tets\")\n",
    "data_dir = './../datasets/dataset1' \n",
    "\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_split + test_split\n",
    ")\n",
    "\n",
    "# Augmentation parameters for specific classes\n",
    "specific_class_augmentation = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=validation_split + test_split\n",
    ")\n",
    "\n",
    "# Generators for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_split / (validation_split + test_split)\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Data preparation for testing\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=test_split / (validation_split + test_split)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "# Oversampling the specified minority classes with augmentation\n",
    "specific_classes = ['1', '2', '3', '4']  # Example specific class indices as strings\n",
    "oversample_ratio = 2  # How many times to oversample the specific classes\n",
    "\n",
    "# Create separate generators for the specific classes with augmentation\n",
    "specific_class_generators = []\n",
    "for cls in specific_classes:\n",
    "    specific_class_generator = specific_class_augmentation.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        classes=[cls],\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    specific_class_generators.append(specific_class_generator)\n",
    "\n",
    "# Function to combine generators\n",
    "def combined_generator(base_generator, specific_class_generators, oversample_ratio):\n",
    "    while True:\n",
    "        x_batch, y_batch = base_generator.next()\n",
    "        for _ in range(oversample_ratio):\n",
    "            specific_class_index = np.random.randint(len(specific_class_generators))\n",
    "            x_specific, y_specific = specific_class_generators[specific_class_index].next()\n",
    "            \n",
    "            # Ensure y_specific matches the shape of y_batch\n",
    "            if y_specific.shape[1] == 1:\n",
    "                y_specific = np.eye(num_classes)[y_specific[:, 0].astype(int)]  # One-hot encode if necessary\n",
    "                \n",
    "            x_batch = np.concatenate((x_batch, x_specific), axis=0)\n",
    "            y_batch = np.concatenate((y_batch, y_specific), axis=0)\n",
    "        \n",
    "        yield x_batch, y_batch\n",
    "\n",
    "# Combined generator for training\n",
    "combined_train_generator = combined_generator(train_generator, specific_class_generators, oversample_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(test_generator.classes), y=test_generator.classes)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights: \", class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom weighted categorical cross-entropy loss function\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        weights_tensor = tf.reduce_sum(weights * y_true, axis=-1)\n",
    "        unweighted_losses = categorical_crossentropy(y_true, y_pred)\n",
    "        weighted_losses = unweighted_losses * weights_tensor\n",
    "        return tf.reduce_mean(weighted_losses)\n",
    "    return loss\n",
    "\n",
    "loss_fn = weighted_categorical_crossentropy(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    return tf.py_function(\n",
    "        func=lambda y_true, y_pred: balanced_accuracy_score(\n",
    "            y_true.numpy(), y_pred.numpy()),\n",
    "        inp=[y_true, y_pred],\n",
    "        Tout=tf.float64)\n",
    "\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), tf.int32)\n",
    "    y_pred = tf.cast(tf.argmax(y_pred, axis=1), tf.int32)\n",
    "\n",
    "    def compute_fscore(y_true, y_pred):\n",
    "        _, _, fscore, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='macro', zero_division=0)\n",
    "        return fscore\n",
    "\n",
    "    return tf.py_function(func=compute_fscore, inp=[y_true, y_pred], Tout=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 3.5e-5\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.AUC(),\n",
    "    balanced_accuracy,\n",
    "    fscore,\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"A single label was found in y_true and y_pred.\")\n",
    "warnings.filterwarnings('ignore', message=\"y_pred contains classes not in y_true\") \n",
    "warnings.filterwarnings('ignore', message=\"A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\") \n",
    "\n",
    "\n",
    "def accuracyGraph(history):\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Assuming 'epochs' is defined and contains the number of epochs\n",
    "    epochs_no = range(epochs)\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_no, train_accuracy, 'b', label='Train Accuracy')\n",
    "    plt.plot(epochs_no, val_accuracy, 'b+', label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_no, train_loss, 'r', label='Train Loss')\n",
    "    plt.plot(epochs_no, val_loss, 'r+', label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(model):\n",
    "    y_true = test_generator.classes\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=list(test_generator.class_indices.keys())))\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "    print(conf_matrix)\n",
    "\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    plot_confusion_matrix(conf_matrix, list(test_generator.class_indices.keys()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the custom loss function\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_fn, metrics=metrics)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    combined_train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    epochs=epochs,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyGraph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metrices = model.evaluate(test_generator)\n",
    "# _metrices = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "\n",
    "print(\"Test Metrices\", _metrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Fine-tuning: Unfreeze some layers of the base model\n",
    "for layer in model.layers[:379]:  # Adjust the index as needed\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[379:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "# model.compile(optimizer=Adam(lr=0.00001), loss=loss_fn, metrics=['accuracy'])\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss=\"categorical_crossentropy\", metrics=metrics)\n",
    "\n",
    "# Continue training (fine-tuning)\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    combined_train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyGraph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metrices = model.evaluate(test_generator)\n",
    "# _metrices = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "\n",
    "print(\"Test Metrices\", _metrices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
